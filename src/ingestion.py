import requests
import pandas as pd
import io
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType, TimestampType

# --- 1. InicializaÃ§Ã£o do Spark ---
spark = SparkSession.builder.appName("OfficialSchemaBronzeIngestion").getOrCreate()
print("âœ… Spark Session iniciada.")

# --- 2. DefiniÃ§Ã£o do Schema Fixo (Baseado no DicionÃ¡rio de Dados Oficial) ---
# Este Ã© o nosso "Contrato de Dados" para a camada Bronze, garantindo consistÃªncia.
official_schema = StructType([
    StructField("VendorID", LongType(), True),
    StructField("tpep_pickup_datetime", TimestampType(), True),
    StructField("tpep_dropoff_datetime", TimestampType(), True),
    StructField("passenger_count", DoubleType(), True), # Usamos Double para seguranÃ§a com nulos
    StructField("trip_distance", DoubleType(), True),
    StructField("RatecodeID", DoubleType(), True), # Usamos Double para seguranÃ§a com nulos
    StructField("store_and_fwd_flag", StringType(), True),
    StructField("PULocationID", LongType(), True),
    StructField("DOLocationID", LongType(), True),
    StructField("payment_type", LongType(), True),
    StructField("fare_amount", DoubleType(), True),
    StructField("extra", DoubleType(), True),
    StructField("mta_tax", DoubleType(), True),
    StructField("tip_amount", DoubleType(), True),
    StructField("tolls_amount", DoubleType(), True),
    StructField("improvement_surcharge", DoubleType(), True),
    StructField("total_amount", DoubleType(), True),
    StructField("congestion_surcharge", DoubleType(), True),
    StructField("airport_fee", DoubleType(), True)
])
print("âœ… Schema oficial definido com sucesso.")

# --- 3. ConfiguraÃ§Ã£o ---
TAXI_TYPE = "yellow"
YEAR = 2023
MONTHS_LIST = list(range(1, 6))
BASE_URL = "https://d37ci6vzurychx.cloudfront.net/trip-data/{type}_tripdata_{year}-{month:02d}.parquet"
TABLE_NAME = "bronze_taxi_trips"
print(f"âš™ï¸ Configurado para ingerir dados de '{TAXI_TYPE}' com schema oficial.")

# --- 4. Loop de IngestÃ£o e Escrita Incremental ---
for month in MONTHS_LIST:
    url = BASE_URL.format(type=TAXI_TYPE, year=YEAR, month=month)
    print(f"ğŸ”„ Processando {url}...")
    
    try:
        # a. Download e leitura para Pandas
        response = requests.get(url)
        response.raise_for_status()
        parquet_file = io.BytesIO(response.content)
        pandas_df = pd.read_parquet(parquet_file)
        
        # b. CriaÃ§Ã£o do Spark DF, forÃ§ando o nosso schema oficial
        # O Spark irÃ¡ converter os tipos do Pandas para os tipos definidos no nosso schema.
        spark_df = spark.createDataFrame(pandas_df, schema=official_schema)
        print(f"  - âœ”ï¸ Sucesso: {pandas_df.shape[0]} registros lidos e conformados ao schema oficial.")
        
        # c. LÃ³gica de escrita incremental
        write_mode = "overwrite"
        if month > MONTHS_LIST[0]:
            write_mode = "append"
            
        print(f"  - ğŸ’¾ Escrevendo dados do mÃªs {month} com o modo: '{write_mode}'...")
        (
            spark_df.write
            .format("delta")
            # Agora que o schema Ã© fixo, nÃ£o precisamos mais da opÃ§Ã£o "mergeSchema"
            .mode(write_mode)
            .saveAsTable(TABLE_NAME)
        )
        print(f"  - ğŸ‰ Dados do mÃªs {month} salvos com sucesso!")
        
        # d. Limpeza da memÃ³ria
        del pandas_df, spark_df, response
        
    except Exception as e:
        print(f"  - âŒ ERRO ao processar o mÃªs {month}: {e}")
        raise e

print("\nâœ¨ Etapa 2 (IngestÃ£o Bronze) concluÃ­da com a abordagem final e mais robusta.")